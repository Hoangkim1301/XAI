{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ed045d8-5486-42f5-b0fd-5333fcc2fb9a",
   "metadata": {},
   "source": [
    "# Week 5: Gradient-based methods\n",
    "Author: Van Bach Nguyen, licensed under the Creative Commons Attribution 3.0 Unported License https://creativecommons.org/licenses/by/3.0/  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66c40e0-4099-466c-b8b5-032c2323083c",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "- [Exercise 1: Saliency Maps](#Ex1)  \n",
    "- [Exercise 2: Gradient-based methods](#Ex2)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b2f2d5-65c6-461b-8f03-4931bd76d610",
   "metadata": {},
   "source": [
    "# Exercise 1: Saliency Maps <a name=\"Ex1\"></a>\n",
    "**Description:**  A saliency map is one of the first gradient-based techniques. The idea behind it is quite simple by using gradients.\n",
    "\n",
    "**Goal:** The primary objective of this exercise is to gain a deep understanding of a Saliency Map and learn how to implement it in practice.\n",
    "\n",
    "**Task:** Write a function that takes a model and an image as inputs and outputs the saliency map for the model's prediction on the given image.\n",
    "\n",
    "**Note:** \n",
    "- You can use the PyTorch or TensorFlow framework.\n",
    "- Printing the results is sufficient.\n",
    "- Pay close attention to the comments within your function. You should ensure that each part of the function corresponds to the respective part of the methodology described in theoretical question 1.\n",
    "- You may need to write the preprocessing function explicitly.\n",
    "- To print the label in a human-readable form (e.g., \"goldfish\" instead of \"label 1\"), you can use the JSON file \"imagenet_class_index.json,\" which contains corresponding text labels for each class. For PyTorch, you may need to use this, while for TensorFlow, you can use \"decode_predictions.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6906da23-52af-4247-aead-40d4ed464483",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Implement the function grade with the description below\n",
    "def saliency_map(model, image=\"dog.jpg\"):\n",
    "    \"\"\"\n",
    "    Generate and print the saliency map for the prediction of the given model on the specified image.\n",
    "\n",
    "    Args:\n",
    "        model: PyTorch or TensorFlow model.\n",
    "        image: The file path of the image.\n",
    "\n",
    "    Returns:\n",
    "        - text label (e.g., \"goldfish,\" \"green lizard,\" \"Pomeranian,\" ...)\n",
    "        - Saliency map of the model's prediction.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfdfd00-dc27-4f53-b36d-825b530faf0e",
   "metadata": {},
   "source": [
    "Now, given the image 'dog.jpg' in this directory and a ResNet50 model (which can be loaded using torchvision or TensorFlow as shown below), use your implemented function to print the saliency map for the model's prediction on the given image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728f3036-a8e3-43c9-a3a7-eff3ac97918c",
   "metadata": {},
   "source": [
    "First, we can visualize the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44440dbb-161d-4ca3-9192-ea2f1d18e921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "input_image = Image.open(\"dog.jpg\")\n",
    "plt.figure()\n",
    "plt.imshow(input_image)  # Convert from tensor to numpy array and rearrange channels\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de35bf2-7baa-473d-95b2-9a8e5ecf9970",
   "metadata": {},
   "source": [
    "**Comment:** looks like samoyed or eskimo dog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13db780-b924-48e0-9d5b-68dbb33b4a95",
   "metadata": {},
   "source": [
    "**Load Model:** You can choose to run one of the following code blocks, depending on whether you are working with TensorFlow or PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce01ed3-cc52-4a7c-9c0c-ca2bc0a69e73",
   "metadata": {},
   "source": [
    "**1. Tensorflow:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035b5bc8-6b36-40ad-b79c-8fd8889d88c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104b991d-0ae1-4e6f-9ed6-e3e905953ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd7d082-59e7-4c24-99c4-5d37a237490f",
   "metadata": {},
   "source": [
    "**2. Pytorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3845ee04-7e77-42ea-a0b3-58350bbf9ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bd3b34-a683-4cfd-b744-5a0cb8f7cb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df398cbc-6e6e-4384-bbbd-3ef94b56342d",
   "metadata": {},
   "source": [
    "Now, we can call the implemented functions; they should return the predicted class (text label) and the saliency map for the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc24ee1-4b22-4324-b64e-21d33fd152d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this once you've completed your implementation.\n",
    "saliency_map(model, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d554d612-fe3f-4d89-bf73-ba3d61f197b5",
   "metadata": {},
   "source": [
    "Interpret your results, do you agree with the prediction of the model and the explanation of the saliency map?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3979388-baef-4276-9c79-7ac4f760f4bc",
   "metadata": {},
   "source": [
    "# Exercise 2: Comparison of Explanations <a name=\"Ex2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab12d26-5d4c-4040-a43f-3ed15b94e971",
   "metadata": {},
   "source": [
    "**Description:**  In this exercise, we will practice using the Saliency library and explore multiple methods to explain a model's predictions. We will compare the results of these gradient-based methods to each other and to perturbation-based methods like LIME and SHAP to assess their agreement with each other and with your own interpretation.\n",
    "\n",
    "**Goal:** The goal is to become familiar with the library for gradient-based methods and understand the qualitative differences between them.\n",
    "\n",
    "**Task:** Explain the model's predictions from Exercise 1 using the following methods from the Saliency library: Vanilla Gradient, SmoothGrad, Integrated Gradients (IG), and Grad CAM. Then, apply SHAP and LIME, which were covered in previous weeks, to further explain the results. Finally, compare all the results and present them in a grid format. Rank the results based on your evaluation. What criteria do you use for this evaluation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffc740e-d446-4f2c-b0ac-c2facadca311",
   "metadata": {},
   "source": [
    "Install Saliency library by executing the command below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f026786-3063-49f3-a4a5-c179b296c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the command below once:\n",
    "!pip install saliency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634a022c-1555-4dd8-937e-d9a5e9d838ab",
   "metadata": {},
   "source": [
    "#### Exercise 2.1\n",
    "Using vanilla gradient method in library to verify your implementation in exercise 1.\n",
    "\n",
    "**Task:** Use vanilla gradient in library to explain the prediction in exercise 1, and then compare with the results of your implementation, are they similar? If not, what could be the reason?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e01906-79c0-4a65-9259-c39348680ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8aec41-9c2f-426a-9f0d-cc9c0e92c6ee",
   "metadata": {},
   "source": [
    "#### Exercise 2.2 \n",
    "Compare all methods, visualize the results, rank them and mention criteria that you used\n",
    "\n",
    "**Task:** \n",
    "- Perform Vanilla Gradient, SmoothGrad, Integrated Gradients (IG), and Grad CAM using the saliency library, as well as SHAP and LIME from the previous week, to explain the model's prediction in Exercise 1.\n",
    "- Visualize the results in a grid format.\n",
    "- Rank the results based on your qualitative evaluations.\n",
    "- Describe the criteria you used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d82044b-4a46-41e5-a57a-c9972f50731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae6453f-3fdf-4a30-846e-39237f915d4e",
   "metadata": {},
   "source": [
    "#### Exercise 2.3\n",
    "Repeat the experiments in Exercise 2.2 using a different image that you select."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009408ea-1104-4e3c-8c0c-db0401dd8839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your implementation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
